import unsloth  # noqa: F401
import textwrap
import base64
import os
import re
import time

from fastapi import FastAPI, Query, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from src.model.melody_processor import MelodyControlLogitsProcessor, NoteTokenizer
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessorList
from unsloth import FastLanguageModel
import uvicorn

# --- ç’°å¢ƒå¤‰æ•°ã«å¿œã˜ã¦Weaveã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ ---
APP_ENV = os.getenv("APP_ENV", "production")  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å®‰å…¨ãª 'production'

if APP_ENV != "production":
    print("ğŸš€ Running in DEVELOPMENT mode. Weave is enabled.")
    try:
        import weave
        import wandb

        weave.init("melody-flow-api-dev")
        op = weave.op  # é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§ã¯å®Ÿéš›ã®weave.opã‚’ä½¿ç”¨
    except ImportError:
        print("âš ï¸  weave is not installed. Running without it.")

        # weaveãŒãªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„ãƒ€ãƒŸãƒ¼ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’å®šç¾©
        def op(*args, **kwargs):
            def decorator(f):
                return f

            if args and callable(args[0]):
                return decorator(args[0])
            return decorator

else:
    print("âœ… Running in PRODUCTION mode. Weave is disabled.")

    # æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ã§ã¯ä½•ã‚‚ã—ãªã„ãƒ€ãƒŸãƒ¼ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’å®šç¾©
    def op(*args, **kwargs):
        def decorator(f):
            return f

        # @op ã¨ @op() ã®ä¸¡æ–¹ã®æ§‹æ–‡ã«å¯¾å¿œ
        if args and callable(args[0]):
            return decorator(args[0])
        return decorator


# --- ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ---
MODEL_NAME = os.getenv("MODEL_NAME", "models/production.pth/")
print(f"ğŸ§  Loading model: {MODEL_NAME}...")
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ”¥ Using device: {DEVICE}")

try:
    MODEL, TOKENIZER = None, None
    if os.path.isdir(MODEL_NAME):
        print("-> Loading as local Unsloth model (4-bit)...")
        MODEL, TOKENIZER = FastLanguageModel.from_pretrained(
            model_name=MODEL_NAME, max_seq_length=4096, dtype=None, load_in_4bit=True
        )
    else:
        print(f"-> Loading as Hugging Face Hub model ({MODEL_NAME})...")
        MODEL = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16).to(
            DEVICE
        )
        TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME)

    NOTE_TOKENIZER_HELPER = NoteTokenizer(TOKENIZER)
    print("âœ… Model loaded successfully.")
except Exception as e:
    print(f"âŒ Fatal: Error loading model: {e}")
    MODEL, TOKENIZER, NOTE_TOKENIZER_HELPER = None, None, None

app = FastAPI(title="Melody Flow Local API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- Weaveã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’æ¡ä»¶ä»˜ãã§é©ç”¨ ---
@op()  # APP_ENVã«å¿œã˜ã¦æœ¬ç‰©ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‹ãƒ€ãƒŸãƒ¼ãŒä½¿ã‚ã‚Œã‚‹
def generate_midi_from_model(
    prompt: str,
    processor: MelodyControlLogitsProcessor,
    seed: int,
    max_new_tokens: int = 128,
    temperature: float = 0.75,
    do_sample: bool = True,
) -> str:
    if not MODEL or not TOKENIZER:
        raise RuntimeError("Model is not loaded.")
    torch.manual_seed(seed)
    inputs = TOKENIZER(prompt, return_tensors="pt").to(DEVICE)
    logits_processors = LogitsProcessorList([processor])
    output = MODEL.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        temperature=temperature,
        pad_token_id=TOKENIZER.eos_token_id,
        logits_processor=logits_processors,
        do_sample=do_sample,
    )

    # é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã®æ™‚ã ã‘Weaveã«æƒ…å ±ã‚’è¨˜éŒ²
    if APP_ENV != "production" and "weave" in globals():
        wandb.summary["allowed_notes"] = processor.note_tokenizer.ids_to_string(
            processor.allowed_token_ids
        )
    return TOKENIZER.decode(output[0])


def parse_and_pickup_notes(decoded_text: str, head_k: int = 5) -> str:
    match = re.search(r"pitch duration wait velocity instrument\s*\n(.*)", decoded_text, re.DOTALL)
    midi_note_data = match.group(1).strip() if match else decoded_text
    notes = [line.split(" ")[0] for line in midi_note_data.split("\n")]
    return " ".join(notes[:head_k])


def parse_and_encode_midi(decoded_text: str) -> str:
    match = re.search(r"pitch duration wait velocity instrument\s*\n(.*)", decoded_text, re.DOTALL)
    midi_note_data = match.group(1).strip() if match else decoded_text
    return base64.b64encode(midi_note_data.encode("utf-8")).decode("utf-8")


@op()  # APP_ENVã«å¿œã˜ã¦æœ¬ç‰©ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‹ãƒ€ãƒŸãƒ¼ãŒä½¿ã‚ã‚Œã‚‹
@app.get("/generate")
def generate_melody(
    response: Response,
    chord_progression: str = Query(..., description="ã‚³ãƒ¼ãƒ‰é€²è¡Œ"),
    style: str = Query(..., description="éŸ³æ¥½ã‚¹ã‚¿ã‚¤ãƒ«"),
    variation: int = Query(1, description="ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼‰"),
    supress_token_prob_ratio: float = Query(
        0.3, ge=0.0, lt=1.0, description="è¨±å¯ã•ã‚Œã¦ã„ãªã„ãƒ”ãƒƒãƒã®ç™ºç”Ÿç¢ºç‡æŠ‘åˆ¶ãƒ¬ã‚·ã‚ª"
    ),
    instrument: str = Query("Alto Saxophone", description="æ¥½å™¨"),
):
    start_time = time.time()
    chords = [chord.strip() for chord in chord_progression.split("-")]
    melodies = {}
    prev_bar_notes = ""

    for bars, chord in enumerate(chords):
        processor = MelodyControlLogitsProcessor(
            chord, NOTE_TOKENIZER_HELPER, supress_token_prob_ratio=supress_token_prob_ratio
        )
        prompt = f"""
            Act as a world-class jazz musician improvising over a chord progression.
            Your task is to generate a single bar of a masterful melodic phrase for
            the specific chord at the current position in the progression.
            - Style: {style}
            - Full Chord Progression: {chord_progression}
            - Current Bar Number: {bars + 1}
            - Chord for This Bar: {chord}
            - Prev Bar Notes: {prev_bar_notes}
            - Instrument: {instrument}
            Generate the melody for this bar only. The output format is:
            pitch duration wait velocity instrument
            """
        prompt = textwrap.dedent(prompt)
        raw_output = generate_midi_from_model(prompt, processor, seed=variation)
        encoded_midi = parse_and_encode_midi(raw_output)
        prev_bar_notes = parse_and_pickup_notes(raw_output)

        key = chord
        count = 2
        while key in melodies:
            key = f"{chord}_{count}"
            count += 1
        melodies[key] = encoded_midi

    print(f"Generated melody in {time.time() - start_time:.2f} seconds for variation {variation}")
    return {"chord_melodies": melodies}


current_dir = os.path.dirname(os.path.abspath(__file__))
static_dir = os.path.join(current_dir, "..", "..", "static")

app.mount("/static", StaticFiles(directory=static_dir), name="static")


@app.get("/", response_class=FileResponse)
async def read_index():
    return FileResponse(os.path.join(static_dir, "index.html"))


def start():
    uvicorn.run("src.api.main:app", host="0.0.0.0", port=8000, reload=True)


if __name__ == "__main__":
    start()
